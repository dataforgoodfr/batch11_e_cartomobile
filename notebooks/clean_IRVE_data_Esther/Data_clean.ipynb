{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets included\n",
    "- \"data_for_viz/consolidation-etalab-irve.csv\": comporte les données des IRVE (https://www.data.gouv.fr/fr/datasets/fichier-consolide-des-bornes-de-recharge-pour-vehicules-electriques/)\n",
    "\n",
    "Dans le but de constituer un répertoire national des Infrastructures de recharge pour véhicules électriques (IRVE), ouvert et accessible à tous, les collectivités locales porteuses d’un projet d’installation d’IRVE doivent, au fur et à mesure de la mise en service des stations, publier sur la plateforme data.gouv.fr les données statiques relatives à la localisation et aux caractéristiques techniques de ces installations selon les modalités définies dans l’arrêté du 4 mai 2021.\n",
    "Etalab consolide l'ensemble des jeux de données produits par les différents acteurs territoriaux sur un jeu de donnée consolidé. Celui-ci a pour objectif d'être le plus exhaustif possible et ambitionne de regrouper l'ensemble des bornes IRVE françaises. Un document décrivant l'ensemble des datasources utilisées pour cette consolidation peut être consulté sur la page data.gouv de la datasource.\n",
    "\n",
    "[Datasource data.gouv](https://www.data.gouv.fr/fr/datasets/fichier-consolide-des-bornes-de-recharge-pour-vehicules-electriques/)\n",
    "\n",
    "- \"data_for_viz/voitures-rechargeables-par-commune-enrichies.csv\": comporte le nombre de voitures immatriculées par commune et par type de charge (https://www.data.gouv.fr/fr/datasets/voitures-particulieres-immatriculees-par-commune-et-par-type-de-recharge/), données enrichies avec le département (https://geo.api.gouv.fr/decoupage-administratif/communes).\n",
    "\n",
    "- \"data_for_viz/communes-departement-region.csv\": dataset comportant les communes de France, avec pour chacune leur département et région\n",
    "\n",
    "- \"data_for_viz/departements.geojson\": comporte la géométrie des départements (https://france-geojson.gregoiredavid.fr/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up environment\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from matplotlib import pyplot as plt\n",
    "#import plotly.figure_factory as ff\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clean IRVE data\n",
    "### 1.A Clean variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prise_type_ef [False  True]\n",
      "prise_type_2 [ True False]\n",
      "prise_type_combo_ccs [False  True]\n",
      "prise_type_chademo [False  True]\n",
      "prise_type_autre [False  True]\n",
      "gratuit [False True nan]\n",
      "paiement_acte [ True False]\n",
      "paiement_cb [False True nan]\n",
      "paiement_autre [True False nan]\n",
      "reservation [False  True]\n",
      "station_deux_roues [False  True]\n",
      "consolidated_is_lon_lat_correct [ True False]\n",
      "consolidated_is_code_insee_verified [ True False]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "puissance_categorie\n",
       "Petite recharge         0.446929\n",
       "Recharge rapide         0.236515\n",
       "Deux-roues              0.162984\n",
       "Tres haute puissance    0.153572\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irve = pd.read_csv(r\"path\\consolidation-etalab-irve-20230526.csv\", sep=',', on_bad_lines='skip', dtype=str)\n",
    "\n",
    "# Clean boolean variables\n",
    "map_to_bool = {\n",
    "    'false': False,\n",
    "    '0': False,\n",
    "    'FALSE': False,\n",
    "    'False': False,\n",
    "    'true': True,\n",
    "    'TRUE': True,\n",
    "    '1': True,\n",
    "    'True': True\n",
    "}\n",
    "\n",
    "bool_columns = ['prise_type_ef', 'prise_type_2', 'prise_type_combo_ccs', 'prise_type_chademo', 'prise_type_autre',\n",
    "               'gratuit', 'paiement_acte', 'paiement_cb', 'paiement_autre', 'reservation', 'station_deux_roues',\n",
    "                'consolidated_is_lon_lat_correct', 'consolidated_is_code_insee_verified']\n",
    "\n",
    "for col in bool_columns:\n",
    "    irve[col] = irve[col].map(map_to_bool)\n",
    "\n",
    "# Check\n",
    "for col in bool_columns:\n",
    "    print(col, irve[col].unique())\n",
    "\n",
    "\n",
    "# Assign other datatypes\n",
    "types_dict = {\n",
    "    'nbre_pdc': int, \n",
    "    'puissance_nominale': float, \n",
    "    'consolidated_longitude': float,\n",
    "    'consolidated_latitude': float,\n",
    "              }\n",
    "\n",
    "for col, col_type in types_dict.items():\n",
    "    irve[col] = irve[col].astype(col_type)\n",
    "\n",
    "\n",
    "# Create categorical variables for power\n",
    "bins = [0, 7.4, 22, 150, float('inf')]\n",
    "labels = ['Deux-roues', 'Petite recharge', 'Recharge rapide', 'Tres haute puissance']\n",
    "irve['puissance_categorie'] = pd.cut(irve['puissance_nominale'], bins=bins, labels=labels)\n",
    "irve['puissance_categorie'].value_counts(normalize=True)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.B Treat Duplicates\n",
    "- Based on what follow, we retain \"point de charge\" as the way to identify a unique charging station.\n",
    "\n",
    "**From Nalron:**\n",
    "Notons que le contexte métier nécessite de la rigueur dans l'interprétation de certaines variables, l'amalgame entre station, borne et point de charge est régulièrement rencontré. Donc, \"id_station\" n'est pas le sous-ensemble le plus approprié à l'identification de doublons, une station de recharge peut avoir plusieurs points de charge, et l'identifiant ne tient pas compte du point de charge. Notons que \"id_pdc_itinerance\" permet d'obtenir des identifiants uniques pouvant cette fois-ci être pris comme sous-ensemble. \n",
    "\n",
    "**Combien de points de charge en France?**\n",
    "Selon la définition de l'AFIREV, le point de charge représente le nombre d'emplacements individuels permettant le stationnement du véhicule pendant le temps de charge, donc le nombre de prises de la borne. Le jeu de données `irve` ne permet pas de le quantifier directement, malgré la présence d'une variable 'nbre_pdc' qui ne représente que la borne et non le nombre de prises.\n",
    "\n",
    "Les articles suivants permettent de se faire une idée de l'évolution du nombre de points de charge en France en 2022 et 2023 : \n",
    "\n",
    "**Article de Février 2023:** [Source](https://www.tressol-chabrier.com/actualites/Le+futur+de+l%E2%80%99automobile/Voiture%2B%25C3%25A9lectrique%2B%253A%2B85%2B284%2Bpoints%2Bde%2Brecharge%2Bdisponibles%2Ben%2BFrance-107) \n",
    "\n",
    "\"85 284, c’est le nombre de points de recharge ouverts au public au 31 janvier 2023. Il est donc aujourd’hui de plus en plus facile de recharger sa voiture électrique. Il s’agit d’une évolution de + 57 % en un an. Si ces efforts se poursuivent, l’objectif pour la France d’atteindre les 100 000 points de recharge est ainsi facilement atteignable.\"\n",
    "\n",
    "\n",
    "**Article de Avril 2022:** [Source](https://www.lesnumeriques.com/voiture/le-chiffre-du-jour-57-732-bornes-de-recharge-pour-voitures-electriques-en-france-n180505.html) \n",
    "\n",
    "\"Il indique que la France peut désormais compter sur 57 732 points de recharge ouverts au public au 31 mars 2022. L'Avere France se satisfait d'un taux d'évolution de 54 % sur 12 mois\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "id_station_itinerance 68360 19415\n",
      "id_station_local 73157 11377\n",
      "id_pdc_itinerance 37469 46594\n",
      "id_pdc_local 46589 29859\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x000001923EFD2D90>\n",
      "0\n",
      "nom_amenageur 7\n",
      "siren_amenageur 972\n",
      "contact_amenageur 1044\n",
      "nom_operateur 77\n",
      "contact_operateur 0\n",
      "telephone_operateur 17093\n",
      "nom_enseigne 0\n",
      "id_station_itinerance 0\n",
      "id_station_local 33548\n",
      "nom_station 0\n",
      "implantation_station 0\n",
      "adresse_station 0\n",
      "code_insee_commune 988\n",
      "coordonneesXY 0\n",
      "nbre_pdc 0\n",
      "id_pdc_itinerance 0\n",
      "id_pdc_local 33918\n",
      "puissance_nominale 0\n",
      "prise_type_ef 0\n",
      "prise_type_2 0\n",
      "prise_type_combo_ccs 0\n",
      "prise_type_chademo 0\n",
      "prise_type_autre 0\n",
      "gratuit 10\n",
      "paiement_acte 0\n",
      "paiement_cb 11\n",
      "paiement_autre 7436\n",
      "tarification 31597\n",
      "condition_acces 0\n",
      "reservation 0\n",
      "horaires 0\n",
      "accessibilite_pmr 0\n",
      "restriction_gabarit 6\n",
      "station_deux_roues 0\n",
      "raccordement 2288\n",
      "num_pdl 20822\n",
      "date_mise_en_service 0\n",
      "observations 17430\n",
      "date_maj 0\n",
      "cable_t2_attache 36016\n",
      "last_modified 0\n",
      "datagouv_dataset_id 0\n",
      "datagouv_resource_id 0\n",
      "datagouv_organization_or_owner 0\n",
      "consolidated_longitude 0\n",
      "consolidated_latitude 0\n",
      "consolidated_code_postal 3770\n",
      "consolidated_commune 2143\n",
      "consolidated_is_lon_lat_correct 0\n",
      "consolidated_is_code_insee_verified 0\n",
      "puissance_categorie 64\n",
      "nom_amenageur 30679\n",
      "siren_amenageur 30598\n",
      "contact_amenageur 27442\n",
      "nom_operateur 35788\n",
      "contact_operateur 28583\n",
      "telephone_operateur 22721\n",
      "nom_enseigne 31699\n",
      "id_station_itinerance 36718\n",
      "id_station_local 35487\n",
      "nom_station 35047\n",
      "implantation_station 36369\n",
      "adresse_station 27477\n",
      "code_insee_commune 34051\n",
      "coordonneesXY 28143\n",
      "nbre_pdc 35620\n",
      "id_pdc_itinerance 37469\n",
      "id_pdc_local 35531\n",
      "puissance_nominale 33261\n",
      "prise_type_ef 35541\n",
      "prise_type_2 34756\n",
      "prise_type_combo_ccs 37110\n",
      "prise_type_chademo 37110\n",
      "prise_type_autre 37072\n",
      "gratuit 30144\n",
      "paiement_acte 30127\n",
      "paiement_cb 36810\n",
      "paiement_autre 30092\n",
      "tarification 34110\n",
      "condition_acces 37453\n",
      "reservation 37413\n",
      "horaires 29990\n",
      "accessibilite_pmr 28745\n",
      "restriction_gabarit 34967\n",
      "station_deux_roues 36615\n",
      "raccordement 33695\n",
      "num_pdl 30079\n",
      "date_mise_en_service 32603\n",
      "observations 35737\n",
      "date_maj 6063\n",
      "cable_t2_attache 35488\n",
      "last_modified 896\n",
      "datagouv_dataset_id 31697\n",
      "datagouv_resource_id 896\n",
      "datagouv_organization_or_owner 34438\n",
      "consolidated_longitude 28458\n",
      "consolidated_latitude 28209\n",
      "consolidated_code_postal 33534\n",
      "consolidated_commune 34148\n",
      "consolidated_is_lon_lat_correct 34568\n",
      "consolidated_is_code_insee_verified 34442\n",
      "puissance_categorie 34613\n"
     ]
    }
   ],
   "source": [
    "# Drop pdc with missing 'date_mise_en_service' --> Needed for time series\n",
    "irve = irve[irve['date_mise_en_service'].isna()==False]\n",
    "print(irve['date_mise_en_service'].isna().sum())\n",
    "\n",
    "# Count duplicates for different possible identifiers\n",
    "identifiers = ['id_station_itinerance', 'id_station_local', 'id_pdc_itinerance', 'id_pdc_local']\n",
    "for col in identifiers:\n",
    "    duplicate_sum=irve[col].duplicated(keep=False).sum()\n",
    "    n_unique=irve[col].nunique()\n",
    "    print(col, duplicate_sum, n_unique)\n",
    "\n",
    "#How many stations in March 2023\n",
    "irve.id_station_itinerance.nunique()\n",
    "\n",
    "#How many charging stations in March 2023.\n",
    "irve.id_pdc_itinerance.nunique()\n",
    "\n",
    "# 47268 charging stations but still 28909 duplicated rows in terms of pdc_itinerance. What to do with them?\n",
    "irve_duplicates = irve[irve['id_pdc_itinerance'].duplicated(keep=False) == True]\n",
    "print(irve_duplicates.groupby('id_pdc_itinerance'))\n",
    "print(irve_duplicates.duplicated().sum())\n",
    "\n",
    "\n",
    "# Trying to understand where duplicates come from:\n",
    "# 1. Is there a variable with specifically many missing values compared to main dataset?\n",
    "for col in irve_duplicates.columns:\n",
    "   print(col, irve_duplicates[col].isna().sum()) \n",
    "\n",
    "# 2. Can we significantly reduce the number of duplicates when filtering duplicates based on another variable in addition to id_pdc_itinerance?\n",
    "for col in irve_duplicates.columns: \n",
    "    n_duplicates = irve_duplicates.duplicated(subset=['id_pdc_itinerance', col], keep=False).sum()\n",
    "    print(col, n_duplicates) \n",
    "    # Yes, based on 'last_modified'\n",
    "\n",
    "irve_duplicates = irve_duplicates.sort_values(['id_pdc_itinerance', 'last_modified'])\n",
    "first_col = 'id_pdc_itinerance'\n",
    "second_col = 'last_modified'\n",
    "rest_cols = irve_duplicates.columns[(irve_duplicates.columns != first_col) & (irve_duplicates.columns != second_col)]\n",
    "reordered_cols = [first_col] + [second_col] + list(rest_cols)\n",
    "irve_duplicates = irve_duplicates.reindex(columns=reordered_cols)\n",
    "\n",
    "# Seems like many duplicates are pdc with same id_pdc_itinerance and different 'last_modified' value --> keep only the last modified in final dataset\n",
    "# 1. Sort rows and columns\n",
    "irve = irve.sort_values(['id_pdc_itinerance', 'last_modified'])\n",
    "first_col = 'id_pdc_itinerance'\n",
    "second_col = 'last_modified'\n",
    "rest_cols = irve.columns[(irve.columns != first_col) & (irve.columns != second_col)]\n",
    "reordered_cols = [first_col] + [second_col] + list(rest_cols)\n",
    "irve = irve.reindex(columns=reordered_cols)\n",
    "\n",
    "# 2. Drop duplicates\n",
    "irve = irve.drop_duplicates('id_pdc_itinerance', keep='last') # rows are ordered by id_pdc_itinerance and last_modified in an increasing order\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.C Deal with missing department/ municipalities data\n",
    "- First we clean the department and municipalities data and merge them with irve\n",
    "- For the 30% irve observations with missing department/ municipalities we input them based on XY coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read department data\n",
    "geojson_dep = gpd.read_file(r\"path\\departements.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read municipalities data\n",
    "df_communes=pd.read_csv(r\"path\\communes-departement-region.csv\", dtype=str)\n",
    "\n",
    "# Clean municipalities data\n",
    "\n",
    "# Clean INSEE municipalities codes (add first missing '0')\n",
    "df_communes.loc[df_communes['code_commune_INSEE'].str.len() == 4, \"code_commune_INSEE\"] = '0' + df_communes['code_commune_INSEE']\n",
    "df_communes.loc[df_communes['code_postal'].str.len() == 4, 'code_postal'] = '0' + df_communes['code_postal']\n",
    "df_communes.loc[df_communes['code_departement'].str.len() == 1, 'code_departement'] = '0' + df_communes['code_departement']\n",
    "df_communes = df_communes[['code_commune_INSEE', 'code_departement', 'nom_departement']]\n",
    "\n",
    "# Drop duplicated INSEE codes\n",
    "df_communes = df_communes.drop_duplicates(subset='code_commune_INSEE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kzf401\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\geopandas\\geodataframe.py:1443: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "# Merge IRVE with municipalities data\n",
    "irve = irve.merge(df_communes, left_on='code_insee_commune', right_on='code_commune_INSEE', how='left')\n",
    "\n",
    "# Count department code NaN  \n",
    "irve['code_departement'].value_counts(ascending=True, dropna=False, normalize=True) #32% observations are NaN\n",
    "\n",
    "# Transform lat/long couple into geometric point\n",
    "irve['point'] = gpd.GeoSeries.from_xy(irve['consolidated_longitude'], \n",
    "                                             irve['consolidated_latitude'])\n",
    "irve = gpd.GeoDataFrame(irve, geometry='point')\n",
    "\n",
    "# Put department code as index in geojson database\n",
    "geojson_dep = geojson_dep.set_index('code')\n",
    "\n",
    "# select stations with missing department \n",
    "missing_dep = irve[irve['code_departement'].isna()]\n",
    "\n",
    "# Convert 'point' columns into \"Point\" Shapely object\n",
    "missing_dep['geometry'] = missing_dep['point'].apply(Point)\n",
    "\n",
    "# Look for department based on whether the department polygon includes the point\n",
    "# For each station with missing department: \n",
    "for i, point in missing_dep.iterrows():\n",
    "    # trouver l'index (code du département) des polygones du DataFrame geopandas des departments qui comportent le point\n",
    "    polygons_containing_point = geojson_dep[geojson_dep['geometry'].contains(point['geometry'])].index.tolist()\n",
    "    # Ajouter le code du département trouvé (si un département a été trouvé)\n",
    "    for polygon_index in polygons_containing_point:\n",
    "        irve.loc[i, 'code_departement'] = polygon_index\n",
    "        break\n",
    "\n",
    "# convert from gpd DataFrame format to Dataframe\n",
    "irve=pd.DataFrame(irve)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.D Additional stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now we leave out the cleaning of NaN for n_amenageur, n_operateur, and n_enseigne done by Nalron\n",
    "\n",
    "# Add info (population, population density and region) at the department level based on 'departements-francais.csv'\n",
    "#Source : https://www.regions-et-departements.fr/departements-francais\n",
    "\n",
    "dpt_fr = pd.read_excel(r\"path\\departements-francais.xls\")\n",
    "\n",
    "# Clean department data\n",
    "dpt_fr.rename(columns={'NUMÉRO': 'code_dpt', 'NOM': 'dpt', 'REGION': 'region',\n",
    "                       'SUPERFICIE (km²)': 'superficie_km2', 'POPULATION': 'nbre_habitants',\n",
    "                       'DENSITE (habitants/km2)': 'hab/km2'}, inplace=True)\n",
    "\n",
    "dpt_fr['code_dpt'] = dpt_fr['code_dpt'].astype('str')\n",
    "dpt_fr.loc[dpt_fr['code_dpt'].str.len() == 1, 'code_dpt'] = '0' + dpt_fr['code_dpt']\n",
    "\n",
    "# Merge irve and additional info on departments\n",
    "irve = irve.merge(dpt_fr[['code_dpt', 'region', 'superficie_km2', 'nbre_habitants', 'hab/km2']], \n",
    "                    how='left', left_on=\"code_departement\", right_on = \"code_dpt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export cleaned irve dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export clean data\n",
    "irve.to_csv(r\"path\\consolidation-etalab-irve-clean.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Irve-based datasets for data viz\n",
    "### 2.A Location-level data for maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Viz: map irve/ department\n",
    "\n",
    "# Group by location\n",
    "pdc_par_loc = irve.groupby(['consolidated_longitude', 'consolidated_latitude']).agg({\n",
    "    'nbre_pdc': 'count',\n",
    "    'code_departement': lambda x: pd.Series.mode(x)\n",
    "}).reset_index()\n",
    "\n",
    "# Re-create point\n",
    "pdc_par_loc['point']= gpd.GeoSeries.from_xy(pdc_par_loc['consolidated_longitude'], \n",
    "                                             pdc_par_loc['consolidated_latitude'])\n",
    "\n",
    "# Replace [] with NaN\n",
    "def find_dep(dep):\n",
    "    if isinstance(dep, str):\n",
    "        return dep\n",
    "    return np.nan\n",
    "\n",
    "pdc_par_loc['code_departement'] = pdc_par_loc['code_departement'].apply(find_dep)\n",
    "\n",
    "# Keep only metropolitan France for viz\n",
    "pdc_par_loc = pdc_par_loc[pdc_par_loc['code_departement'].astype(str).apply(len)<3]\n",
    "\n",
    "# Export file for data viz\n",
    "pdc_par_loc.to_csv(r'path\\irve_par_loc.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.B Time series data for evolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un timeseries du nombre de stations de recharge au cours du temps\n",
    "\n",
    "# remplacer les dates aberrantes par des valeurs nulles\n",
    "irve.loc[(irve['date_mise_en_service']>'2024') | (irve['date_mise_en_service']<'2001'), \n",
    "         'date_mise_en_service'] = np.nan\n",
    "\n",
    "# convertir la colonne en datetime\n",
    "irve['date_mise_en_service'] = pd.to_datetime(irve['date_mise_en_service'], format=\"%Y-%m-%d\")\n",
    "\n",
    "# grouper par mois, appliquer une somme cumulative sur le nombre de stations et de points de charge\n",
    "irve.set_index('date_mise_en_service', inplace=True)\n",
    "irve_ts = (irve.groupby(pd.Grouper(freq=\"M\")).nbre_pdc\n",
    "               .agg(['count', 'sum'])\n",
    "               .add_prefix('nbre_pdc_')\n",
    "               .cumsum()\n",
    "               .reset_index())\n",
    "\n",
    "irve_ts = (irve.groupby(pd.Grouper(freq=\"M\")).agg({\n",
    "    'id_station_itinerance': 'nunique',\n",
    "    'id_pdc_itinerance': 'nunique'\n",
    "}).cumsum().reset_index()).rename(columns={'id_station_itinerance': 'nb_stations',\n",
    "                                           'id_pdc_itinerance': 'nb_pdc'})\n",
    "\n",
    "# exporter le fichier\n",
    "irve_ts.to_csv(r'path\\irve_time_series.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
