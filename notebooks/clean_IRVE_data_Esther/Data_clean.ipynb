{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets included\n",
    "- \"data_for_viz/consolidation-etalab-irve.csv\": comporte les données des IRVE (https://www.data.gouv.fr/fr/datasets/fichier-consolide-des-bornes-de-recharge-pour-vehicules-electriques/)\n",
    "\n",
    "Dans le but de constituer un répertoire national des Infrastructures de recharge pour véhicules électriques (IRVE), ouvert et accessible à tous, les collectivités locales porteuses d’un projet d’installation d’IRVE doivent, au fur et à mesure de la mise en service des stations, publier sur la plateforme data.gouv.fr les données statiques relatives à la localisation et aux caractéristiques techniques de ces installations selon les modalités définies dans l’arrêté du 4 mai 2021.\n",
    "Etalab consolide l'ensemble des jeux de données produits par les différents acteurs territoriaux sur un jeu de donnée consolidé. Celui-ci a pour objectif d'être le plus exhaustif possible et ambitionne de regrouper l'ensemble des bornes IRVE françaises. Un document décrivant l'ensemble des datasources utilisées pour cette consolidation peut être consulté sur la page data.gouv de la datasource.\n",
    "\n",
    "[Datasource data.gouv](https://www.data.gouv.fr/fr/datasets/fichier-consolide-des-bornes-de-recharge-pour-vehicules-electriques/)\n",
    "\n",
    "- \"data_for_viz/voitures-rechargeables-par-commune-enrichies.csv\": comporte le nombre de voitures immatriculées par commune et par type de charge (https://www.data.gouv.fr/fr/datasets/voitures-particulieres-immatriculees-par-commune-et-par-type-de-recharge/), données enrichies avec le département (https://geo.api.gouv.fr/decoupage-administratif/communes).\n",
    "\n",
    "- \"data_for_viz/communes-departement-region.csv\": dataset comportant les communes de France, avec pour chacune leur département et région\n",
    "\n",
    "- \"data_for_viz/departements.geojson\": comporte la géométrie des départements (https://france-geojson.gregoiredavid.fr/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up environment\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from matplotlib import pyplot as plt\n",
    "#import plotly.figure_factory as ff\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clean IRVE data\n",
    "### 1.A Clean variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prise_type_ef [False  True]\n",
      "prise_type_2 [False  True]\n",
      "prise_type_combo_ccs [ True False]\n",
      "prise_type_chademo [False  True]\n",
      "prise_type_autre [False  True]\n",
      "gratuit [False True nan]\n",
      "paiement_acte [ True False]\n",
      "paiement_cb [True False nan]\n",
      "paiement_autre [True False nan]\n",
      "reservation [ True False]\n",
      "station_deux_roues [False  True]\n",
      "consolidated_is_lon_lat_correct [ True False]\n",
      "consolidated_is_code_insee_verified [ True False]\n"
     ]
    }
   ],
   "source": [
    "irve = pd.read_csv(r\"path\\consolidation-etalab-irve.csv\", sep=',', on_bad_lines='skip', dtype=str)\n",
    "\n",
    "# Clean boolean variables\n",
    "map_to_bool = {\n",
    "    'false': False,\n",
    "    '0': False,\n",
    "    'FALSE': False,\n",
    "    'False': False,\n",
    "    'true': True,\n",
    "    'TRUE': True,\n",
    "    '1': True,\n",
    "    'True': True\n",
    "}\n",
    "\n",
    "bool_columns = ['prise_type_ef', 'prise_type_2', 'prise_type_combo_ccs', 'prise_type_chademo', 'prise_type_autre',\n",
    "               'gratuit', 'paiement_acte', 'paiement_cb', 'paiement_autre', 'reservation', 'station_deux_roues',\n",
    "                'consolidated_is_lon_lat_correct', 'consolidated_is_code_insee_verified']\n",
    "\n",
    "for col in bool_columns:\n",
    "    irve[col] = irve[col].map(map_to_bool)\n",
    "\n",
    "# Check\n",
    "for col in bool_columns:\n",
    "    print(col, irve[col].unique())\n",
    "\n",
    "\n",
    "# Assign other datatypes\n",
    "types_dict = {\n",
    "    'nbre_pdc': int, \n",
    "    'puissance_nominale': float, \n",
    "    'consolidated_longitude': float,\n",
    "    'consolidated_latitude': float,\n",
    "              }\n",
    "\n",
    "for col, col_type in types_dict.items():\n",
    "    irve[col] = irve[col].astype(col_type)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.B Treat Duplicates\n",
    "- Based on what follow, we retain \"point de charge\" as the way to identify a unique charging station.\n",
    "\n",
    "**From Nalron:**\n",
    "Notons que le contexte métier nécessite de la rigueur dans l'interprétation de certaines variables, l'amalgame entre station, borne et point de charge est régulièrement rencontré. Donc, \"id_station\" n'est pas le sous-ensemble le plus approprié à l'identification de doublons, une station de recharge peut avoir plusieurs points de charge, et l'identifiant ne tient pas compte du point de charge. Notons que \"id_pdc_itinerance\" permet d'obtenir des identifiants uniques pouvant cette fois-ci être pris comme sous-ensemble. \n",
    "\n",
    "**Combien de points de charge en France?**\n",
    "Selon la définition de l'AFIREV, le point de charge représente le nombre d'emplacements individuels permettant le stationnement du véhicule pendant le temps de charge, donc le nombre de prises de la borne. Le jeu de données `irve` ne permet pas de le quantifier directement, malgré la présence d'une variable 'nbre_pdc' qui ne représente que la borne et non le nombre de prises.\n",
    "\n",
    "Les articles suivants permettent de se faire une idée de l'évolution du nombre de points de charge en France en 2022 et 2023 : \n",
    "\n",
    "**Article de Février 2023:** [Source](https://www.tressol-chabrier.com/actualites/Le+futur+de+l%E2%80%99automobile/Voiture%2B%25C3%25A9lectrique%2B%253A%2B85%2B284%2Bpoints%2Bde%2Brecharge%2Bdisponibles%2Ben%2BFrance-107) \n",
    "\n",
    "\"85 284, c’est le nombre de points de recharge ouverts au public au 31 janvier 2023. Il est donc aujourd’hui de plus en plus facile de recharger sa voiture électrique. Il s’agit d’une évolution de + 57 % en un an. Si ces efforts se poursuivent, l’objectif pour la France d’atteindre les 100 000 points de recharge est ainsi facilement atteignable.\"\n",
    "\n",
    "\n",
    "**Article de Avril 2022:** [Source](https://www.lesnumeriques.com/voiture/le-chiffre-du-jour-57-732-bornes-de-recharge-pour-voitures-electriques-en-france-n180505.html) \n",
    "\n",
    "\"Il indique que la France peut désormais compter sur 57 732 points de recharge ouverts au public au 31 mars 2022. L'Avere France se satisfait d'un taux d'évolution de 54 % sur 12 mois\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_station_itinerance 36594 18726\n",
      "id_station_local 44396 10923\n",
      "id_pdc_itinerance 11731 43589\n",
      "id_pdc_local 27253 28066\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x000002AD51F95B90>\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Count duplicates for different possible identifiers\n",
    "identifiers = ['id_station_itinerance', 'id_station_local', 'id_pdc_itinerance', 'id_pdc_local']\n",
    "for col in identifiers:\n",
    "    duplicate_sum=irve[col].duplicated().sum()\n",
    "    n_unique=irve[col].nunique()\n",
    "    print(col, duplicate_sum, n_unique)\n",
    "\n",
    "#How many stations in March 2023\n",
    "irve.id_station_itinerance.nunique()\n",
    "\n",
    "#How many charging stations in March 2023.\n",
    "irve.id_pdc_itinerance.nunique()\n",
    "\n",
    "# 43589 charging stations but still 11731 duplicates. What to do with them?\n",
    "irve_duplicates = irve[irve['id_pdc_itinerance'].duplicated() == True]\n",
    "print(irve_duplicates.groupby('id_pdc_itinerance'))\n",
    "print(irve_duplicates.duplicated().sum())\n",
    "\n",
    "# Among duplicated id_pdc_itinerance, all of them differ by at least one variable --> Keep all of them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.C Deal with missing department/ municipalities data\n",
    "- First we clean the department and municipalities data and merge them with irve\n",
    "- For the 30% irve observations with missing department/ municipalities we input them based on XY coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read department data\n",
    "geojson_dep = gpd.read_file(r\"path\\departements.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read municipalities data\n",
    "df_communes=pd.read_csv(r\"path\\communes-departement-region.csv\", dtype=str)\n",
    "\n",
    "# Clean municipalities data\n",
    "\n",
    "# Clean INSEE municipalities codes (add first missing '0')\n",
    "df_communes.loc[df_communes['code_commune_INSEE'].str.len() == 4, \"code_commune_INSEE\"] = '0' + df_communes['code_commune_INSEE']\n",
    "df_communes.loc[df_communes['code_postal'].str.len() == 4, 'code_postal'] = '0' + df_communes['code_postal']\n",
    "df_communes.loc[df_communes['code_departement'].str.len() == 1, 'code_departement'] = '0' + df_communes['code_departement']\n",
    "df_communes = df_communes[['code_commune_INSEE', 'code_departement', 'nom_departement']]\n",
    "\n",
    "# Drop duplicated INSEE codes\n",
    "df_communes = df_communes.drop_duplicates(subset='code_commune_INSEE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kzf401\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\geopandas\\geodataframe.py:1443: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "# Merge IRVE with municipalities data\n",
    "irve = irve.merge(df_communes, left_on='code_insee_commune', right_on='code_commune_INSEE', how='left')\n",
    "\n",
    "# Count department code NaN  \n",
    "irve['code_departement'].value_counts(ascending=True, dropna=False, normalize=True) #32% observations are NaN\n",
    "\n",
    "# Transform lat/long couple into geometric point\n",
    "irve['point'] = gpd.GeoSeries.from_xy(irve['consolidated_longitude'], \n",
    "                                             irve['consolidated_latitude'])\n",
    "irve = gpd.GeoDataFrame(irve, geometry='point')\n",
    "\n",
    "# Put department code as index in geojson database\n",
    "geojson_dep = geojson_dep.set_index('code')\n",
    "\n",
    "# select stations with missing department \n",
    "missing_dep = irve[irve['code_departement'].isna()]\n",
    "\n",
    "# Convert 'point' columns into \"Point\" Shapely object\n",
    "missing_dep['geometry'] = missing_dep['point'].apply(Point)\n",
    "\n",
    "# Look for department based on whether the department polygon includes the point\n",
    "# For each station with missing department: \n",
    "for i, point in missing_dep.iterrows():\n",
    "    # trouver l'index (code du département) des polygones du DataFrame geopandas des departments qui comportent le point\n",
    "    polygons_containing_point = geojson_dep[geojson_dep['geometry'].contains(point['geometry'])].index.tolist()\n",
    "    # Ajouter le code du département trouvé (si un département a été trouvé)\n",
    "    for polygon_index in polygons_containing_point:\n",
    "        irve.loc[i, 'code_departement'] = polygon_index\n",
    "        break\n",
    "\n",
    "# convert from gpd DataFrame format to Dataframe\n",
    "irve=pd.DataFrame(irve)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.D Additional stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now we leave out the cleaning of NaN for n_amenageur, n_operateur, and n_enseigne done by Nalron\n",
    "\n",
    "# Add info (population, population density and region) at the department level based on 'departements-francais.csv'\n",
    "#Source : https://www.regions-et-departements.fr/departements-francais\n",
    "\n",
    "dpt_fr = pd.read_excel(r\"path\\departements-francais.xls\")\n",
    "\n",
    "# Clean department data\n",
    "dpt_fr.rename(columns={'NUMÉRO': 'code_dpt', 'NOM': 'dpt', 'REGION': 'region',\n",
    "                       'SUPERFICIE (km²)': 'superficie_km2', 'POPULATION': 'nbre_habitants',\n",
    "                       'DENSITE (habitants/km2)': 'hab/km2'}, inplace=True)\n",
    "\n",
    "dpt_fr['code_dpt'] = dpt_fr['code_dpt'].astype('str')\n",
    "dpt_fr.loc[dpt_fr['code_dpt'].str.len() == 1, 'code_dpt'] = '0' + dpt_fr['code_dpt']\n",
    "\n",
    "# Merge irve and additional info on departments\n",
    "irve = irve.merge(dpt_fr[['code_dpt', 'region', 'superficie_km2', 'nbre_habitants', 'hab/km2']], \n",
    "                    how='left', left_on=\"code_departement\", right_on = \"code_dpt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export cleaned irve dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export clean data\n",
    "irve.to_csv(r'path\\consolidation-etalab-irve-clean.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Irve-based datasets for data viz\n",
    "### 2.A Location-level data for maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Viz: map irve/ department\n",
    "\n",
    "# Group by location\n",
    "pdc_par_loc = irve.groupby(['consolidated_longitude', 'consolidated_latitude']).agg({\n",
    "    'nbre_pdc': 'count',\n",
    "    'code_departement': lambda x: pd.Series.mode(x)\n",
    "}).reset_index()\n",
    "\n",
    "# Re-create point\n",
    "pdc_par_loc['point']= gpd.GeoSeries.from_xy(pdc_par_loc['consolidated_longitude'], \n",
    "                                             pdc_par_loc['consolidated_latitude'])\n",
    "\n",
    "# Replace [] with NaN\n",
    "def find_dep(dep):\n",
    "    if isinstance(dep, str):\n",
    "        return dep\n",
    "    return np.nan\n",
    "\n",
    "pdc_par_loc['code_departement'] = pdc_par_loc['code_departement'].apply(find_dep)\n",
    "\n",
    "# Keep only metropolitan France for viz\n",
    "pdc_par_loc = pdc_par_loc[pdc_par_loc['code_departement'].astype(str).apply(len)<3]\n",
    "\n",
    "# Export file for data viz\n",
    "pdc_par_loc.to_csv(r'path\\irve_par_loc.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.B Time series data for evolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un timeseries du nombre de stations de recharge au cours du temps\n",
    "\n",
    "# remplacer les dates aberrantes par des valeurs nulles\n",
    "irve.loc[(irve['date_mise_en_service']>'2024') | (irve['date_mise_en_service']<'2001'), \n",
    "         'date_mise_en_service'] = np.nan\n",
    "\n",
    "# convertir la colonne en datetime\n",
    "irve['date_mise_en_service'] = pd.to_datetime(irve['date_mise_en_service'], format=\"%Y-%m-%d\")\n",
    "\n",
    "# grouper par mois, appliquer une somme cumulative sur le nombre de stations et de points de charge\n",
    "irve.set_index('date_mise_en_service', inplace=True)\n",
    "irve_ts = (irve.groupby(pd.Grouper(freq=\"M\")).nbre_pdc\n",
    "               .agg(['count', 'sum'])\n",
    "               .add_prefix('nbre_pdc_')\n",
    "               .cumsum()\n",
    "               .reset_index())\n",
    "\n",
    "irve_ts = (irve.groupby(pd.Grouper(freq=\"M\")).agg({\n",
    "    'id_station_itinerance': 'nunique',\n",
    "    'id_pdc_itinerance': 'nunique'\n",
    "}).cumsum().reset_index()).rename(columns={'id_station_itinerance': 'nb_stations',\n",
    "                                           'id_pdc_itinerance': 'nb_pdc'})\n",
    "\n",
    "# exporter le fichier\n",
    "irve_ts.to_csv(r'path\\irve_time_series.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
