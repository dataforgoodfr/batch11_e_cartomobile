{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auteur: Michaël Leroy\n",
    "\n",
    "Creation du graph routier:\n",
    "    - recuperation pa dep\n",
    "    - ajout dstance et durées avant simplification\n",
    "    - simplification \n",
    "    - concatenation de tous les graph departementaux\n",
    "\n",
    "Sortie:\n",
    "    geodataframe:\n",
    "        - nodes : intersections\n",
    "        - edges : reseau routier    \n",
    "\n",
    "[+] API: \n",
    "    \n",
    "    - Nominatim: https://nominatim.openstreetmap.org/\n",
    "        * obtention des surfaces en shapely geometries\n",
    "    - OpenStreetMaps :\n",
    "        * Lib OSMnx, obtention des résaux routiers sous forme de graph \n",
    "    - OpenChargeMap : \n",
    "        * Points de charge EV (data.gouv et autres)        \n",
    "\n",
    "[+] Méthodologie\n",
    "\n",
    "    - Récupération des réseaux routiers:\n",
    "        * Nodes: position des intersections routières\n",
    "        * Edges: shapely LineString, distance, limitation de vitesse, types de voies...\n",
    "  (  - Récupération des bornes EV\n",
    "        * Création d'un noeud sur l'edge le plus proche\n",
    "        * Split Linestring\n",
    "        # Branchement du noeud et raccord aus deux noeud 'parents' ) le code est présent mais plus utilisé\n",
    "\n",
    "[+] Est produit:\n",
    "        \n",
    "        * Un graph avec:\n",
    "            Nodes : intersections routières\n",
    "            Edges : tronçons entre intersections\n",
    "\n",
    "[+] Limitations:\n",
    "\n",
    "        * On ne peut pas arriver à avoir au moins une route par commune, les orphelines sont ratachées à la route la plus proche dans la suite du traitement\n",
    "\n",
    "[+] Utilité\n",
    "\n",
    "    - Graph Stats:\n",
    "        betweeness, closeness.....\n",
    "\n",
    "[+] Récupération des données par département pour éviter OOM \n",
    "\n",
    "https://wiki.openstreetmap.org/wiki/Key:highway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    area = [\n",
    "        'Auvergne-Rhône-Alpes',\n",
    "    'Bourgogne-Franche-Comté',\n",
    "    'Brittany',\n",
    "    'Centre-Val de Loire',\n",
    "    'Grand Est',\n",
    "    'Hauts-de-France',\n",
    "    'Île-de-France',\n",
    "    'Normandie',\n",
    "    'Nouvelle-Aquitaine',\n",
    "    'Occitanie',\n",
    "    'Pays de la Loire',\n",
    "    'Provence-Alpes-Côte d\\'Azur'\n",
    "]\n",
    "    area_name = 'france'      #'_'.join(area)\n",
    "\n",
    "    \n",
    "\n",
    "    bornes = False\n",
    "\n",
    "    viz = True\n",
    "\n",
    "    roads = (\n",
    "        '|motorway'\n",
    "        '|motorway_link'\n",
    "        '|trunk'\n",
    "        '|trunk_link'\n",
    "        '|primary'\n",
    "        '|primary_link'\n",
    "        '|secondary'\n",
    "        '|secondary_link'\n",
    "        '|tertiary'\n",
    "        #  '|tertiary_link'\n",
    "    )\n",
    "\n",
    "        # '|primary'\n",
    "        # '|motorway_link'\n",
    "        \n",
    "        # '|primary_link'\n",
    "\n",
    "        # '|secondary'\n",
    "        # '|secondary_link'\n",
    "        \n",
    "        \n",
    "        #  '|tertiary'\n",
    "        #  '|tertiary_link'\n",
    "\n",
    "    data_path = './osm_datas/'\n",
    "\n",
    "import joblib\n",
    "joblib.dump(CFG.area, 'CFG.pkl')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG.area_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "\n",
    "\n",
    "%aimport OSM_helper_functions\n",
    "%aimport OCM_helper_functions\n",
    "\n",
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "from tqdm.notebook import tqdm\n",
    "from OSM_helper_functions import *\n",
    "from OCM_helper_functions import *\n",
    "\n",
    "\n",
    "ox.settings.log_console=True\n",
    "ox.settings.use_cache=True\n",
    "''' To retrieve http data from OSMnx and cache them locally\n",
    "    before building graph. Raise and exception if requests\n",
    "    are all done. intercept then set to False and retry.'''\n",
    "# ox.settings.cache_only_mode=True \n",
    "\n",
    "Administratives = {\n",
    "    'Auvergne-Rhône-Alpes': ['Ain', 'Allier', 'Ardèche', 'Cantal', 'Drôme', 'Isère', 'Loire', 'Haute-Loire', 'Puy-de-Dôme', 'Rhône', 'Savoie', 'Haute-Savoie'],\n",
    "    'Bourgogne-Franche-Comté': ['Côte-d\\'Or', 'Doubs', 'Jura', 'Nièvre', 'Haute-Saône', 'Saône-et-Loire', 'Yonne', 'Territoire de Belfort'],\n",
    "    'Brittany': ['Côtes-d\\'Armor', 'Finistère', 'Ille-et-Vilaine', 'Morbihan'],\n",
    "    'Centre-Val de Loire': ['Cher', 'Eure-et-Loir', 'Indre', 'Indre-et-Loire', 'Loir-et-Cher', 'Loiret'],\n",
    "    # 'Corse': ['Corse-du-Sud', 'Haute-Corse'],\n",
    "    'Grand Est': ['Ardennes', 'Aube', 'Marne', 'Haute-Marne', 'Meurthe-et-Moselle', 'Meuse', 'Moselle', 'Bas-Rhin', 'Haut-Rhin', 'Vosges'],\n",
    "    'Hauts-de-France': ['Aisne', 'Nord', 'Oise', 'Pas-de-Calais', 'Somme'],\n",
    "    'Île-de-France': ['Paris', 'Seine-et-Marne', 'Yvelines', 'Essonne', 'Hauts-de-Seine', 'Seine-Saint-Denis', 'Val-de-Marne', 'Val-d\\'Oise'],\n",
    "    'Normandie': ['Calvados', 'Eure', 'Manche', 'Orne', 'Seine-Maritime'],\n",
    "    'Nouvelle-Aquitaine': ['Charente', 'Charente-Maritime', 'Corrèze', 'Creuse', 'Dordogne', 'Gironde', 'Landes', 'Lot-et-Garonne', 'Pyrénées-Atlantiques', 'Deux-Sèvres', 'Vienne', 'Haute-Vienne'],\n",
    "    'Occitanie': ['Ariège', 'Aude', 'Aveyron', 'Gard', 'Haute-Garonne', 'Gers', 'Hérault', 'Lot', 'Lozère', 'Hautes-Pyrénées', 'Pyrénées-Orientales', 'Tarn', 'Tarn-et-Garonne'],\n",
    "    'Pays de la Loire': ['Loire-Atlantique', 'Maine-et-Loire', 'Mayenne', 'Sarthe', 'Vendée'],\n",
    "    'Provence-Alpes-Côte d\\'Azur': ['Alpes-de-Haute-Provence', 'Hautes-Alpes', 'Alpes-Maritimes', 'Bouches-du-Rhône', 'Var', 'Vaucluse']\n",
    "}\n",
    "\n",
    "Regions = [\n",
    "    'Auvergne-Rhône-Alpes',\n",
    "    'Bourgogne-Franche-Comté',\n",
    "    'Brittany',\n",
    "    'Centre-Val de Loire',\n",
    "    # 'Corse',\n",
    "    'Grand Est',\n",
    "    'Hauts-de-France',\n",
    "    'Île-de-France',\n",
    "    'Normandie',\n",
    "    'Nouvelle-Aquitaine',\n",
    "    'Occitanie',\n",
    "    'Pays de la Loire',\n",
    "    'Provence-Alpes-Côte d\\'Azur'\n",
    "]\n",
    "\n",
    "Name2num = {\n",
    "    'Ain': '01',\n",
    "    'Aisne': '02',\n",
    "    'Allier': '03',\n",
    "    'Alpes-de-Haute-Provence': '04',\n",
    "    'Hautes-Alpes': '05',\n",
    "    'Alpes-Maritimes': '06',\n",
    "    'Ardèche': '07',\n",
    "    'Ardennes': '08',\n",
    "    'Ariège': '09',\n",
    "    'Aube': '10',\n",
    "    'Aude': '11',\n",
    "    'Aveyron': '12',\n",
    "    'Bouches-du-Rhône': '13',\n",
    "    'Calvados': '14',\n",
    "    'Cantal': '15',\n",
    "    'Charente': '16',\n",
    "    'Charente-Maritime': '17',\n",
    "    'Cher': '18',\n",
    "    'Corrèze': '19',\n",
    "    'Corse-du-Sud': '2A',\n",
    "    'Haute-Corse': '2B',\n",
    "    'Côte-d\\'Or': '21',\n",
    "    'Côtes-d\\'Armor': '22',\n",
    "    'Creuse': '23',\n",
    "    'Dordogne': '24',\n",
    "    'Doubs': '25',\n",
    "    'Drôme': '26',\n",
    "    'Eure': '27',\n",
    "    'Eure-et-Loir': '28',\n",
    "    'Finistère': '29',\n",
    "    'Gard': '30',\n",
    "    'Haute-Garonne': '31',\n",
    "    'Gers': '32',\n",
    "    'Gironde': '33',\n",
    "    'Hérault': '34',\n",
    "    'Ille-et-Vilaine': '35',\n",
    "    'Indre': '36',\n",
    "    'Indre-et-Loire': '37',\n",
    "    'Isère': '38',\n",
    "    'Jura': '39',\n",
    "    'Landes': '40',\n",
    "    'Loir-et-Cher': '41',\n",
    "    'Loire': '42',\n",
    "    'Haute-Loire': '43',\n",
    "    'Loire-Atlantique': '44',\n",
    "    'Loiret': '45',\n",
    "    'Lot': '46',\n",
    "    'Lot-et-Garonne': '47',\n",
    "    'Lozère': '48',\n",
    "    'Maine-et-Loire': '49',\n",
    "    'Manche': '50',\n",
    "    'Marne': '51',\n",
    "    'Haute-Marne': '52',\n",
    "    'Mayenne': '53',\n",
    "    'Meurthe-et-Moselle': '54',\n",
    "    'Meuse': '55',\n",
    "    'Morbihan': '56',\n",
    "    'Moselle': '57',\n",
    "    'Nièvre': '58',\n",
    "    'Nord': '59',\n",
    "    'Oise': '60',\n",
    "    'Orne': '61',\n",
    "    'Pas-de-Calais': '62',\n",
    "    'Puy-de-Dôme': '63',\n",
    "    'Pyrénées-Atlantiques': '64',\n",
    "    'Hautes-Pyrénées': '65',\n",
    "    'Pyrénées-Orientales': '66',\n",
    "    'Bas-Rhin': '67',\n",
    "    'Haut-Rhin': '68',\n",
    "    'Rhône': '69',\n",
    "    'Haute-Saône': '70',\n",
    "    'Saône-et-Loire': '71',\n",
    "    'Sarthe': '72',\n",
    "    'Savoie': '73',\n",
    "    'Haute-Savoie': '74',\n",
    "    'Paris': '75',\n",
    "    'Seine-Maritime': '76',\n",
    "    'Seine-et-Marne': '77',\n",
    "    'Yvelines': '78',\n",
    "    'Deux-Sèvres': '79',\n",
    "    'Somme': '80',\n",
    "    'Tarn': '81',\n",
    "    'Tarn-et-Garonne': '82',\n",
    "    'Var': '83',\n",
    "    'Vaucluse': '84',\n",
    "    'Vendée': '85',\n",
    "    'Vienne': '86',\n",
    "    'Haute-Vienne': '87',\n",
    "    'Vosges': '88',\n",
    "    'Yonne': '89',\n",
    "    'Territoire de Belfort': '90',\n",
    "    'Essonne': '91',\n",
    "    'Hauts-de-Seine': '92',\n",
    "    'Seine-Saint-Denis': '93',\n",
    "    'Val-de-Marne': '94',\n",
    "    'Val-d\\'Oise': '95'\n",
    "}\n",
    "\n",
    "\n",
    "AREA = []\n",
    "for area in CFG.area:\n",
    "    AREA.extend(Administratives[area] )\n",
    "AREA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listes des découpages Régions Départements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_regions = [\n",
    "#     # 'Larzicourt',\n",
    "#     # 'Arrigny'\n",
    "#     # 'Reims'\n",
    "#     # 'Lot',\n",
    "#     # 'Aube',\n",
    "#     'Ardennes',\n",
    "#     # 'Marne',\n",
    "#     # 'Haute-Marne',\n",
    "#     # 'Côtes-d\\'Armor',\n",
    "#     # 'Bretagne',\n",
    "#     # 'Île-de-France'\n",
    "#     # 'Grand Est', \n",
    "#     # 'Hauts-de-France',\n",
    "#     # 'Bourgogne-Franche-Comté',\n",
    "#     # 'Auvergne-Rhône-Alpes',\n",
    "#     # 'Provence-Alpes-Côte d\\'Azur'\n",
    "\n",
    "# ]\n",
    "# # selected_regions = CFG.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    selection = []\n",
    "    for reg in CFG.area:\n",
    "        selection += Administratives[reg]\n",
    "except:\n",
    "    print('Not a Région')\n",
    "    selection= CFG.area\n",
    "selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph construction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG.roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By graphs\n",
    "file = os.path.join(CFG.data_path, f'[{CFG.area_name}]graph.graphml')\n",
    "try:\n",
    "    print(f'Loading graphfor {CFG.area_name} from disk...', end='  ')\n",
    "    G = ox.io.load_graphml(file)\n",
    "    print(f'{G.number_of_nodes()} nodes, {G.number_of_edges()} edges')\n",
    "\n",
    "except:\n",
    "    print('Datas not found')\n",
    "    G = nx.MultiDiGraph()\n",
    "    stats = {}\n",
    "    total = len(AREA)\n",
    "    print(CFG.roads)\n",
    "    for n, area in enumerate(AREA):\n",
    "        print(f'Datas retrieved for {area}: {n+1}/{total} ~ {(n+1) / total:.2%}')\n",
    "        G_ = get_graph(area, custom_filter=CFG.roads)\n",
    "        G_ = fill_missing_edge_geometry(G_)\n",
    "        G = nx.compose(G, G_)\n",
    "        stats[area] = (G_.number_of_nodes(), G_.number_of_edges()   )\n",
    "        del G_\n",
    "    display(stats)\n",
    "    print(f'before:          {G.number_of_nodes()} nodes, {G.number_of_edges()} edges.')\n",
    "    G =  ox.utils_graph.get_largest_component(G, strongly=True)\n",
    "    print(f'keep largest:    {G.number_of_nodes()} nodes, {G.number_of_edges()} edges.')\n",
    "    G =  ox.utils_graph.remove_isolated_nodes(G)\n",
    "    print(f'remove isolated: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges.')\n",
    "\n",
    "    ox.io.save_graphml(G, file) \n",
    "\n",
    "nodes, edges = ox.graph_to_gdfs(G, nodes=True, edges=True)\n",
    "# G.number_of_nodes(), G.number_of_edges()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.shape, edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(nodes, os.path.join(CFG.data_path, f'[{CFG.area_name}]Gnodes.pkl'),compress=3)\n",
    "\n",
    "joblib.dump(edges, os.path.join(CFG.data_path, f'[{CFG.area_name}]Gedges.pkl'),compress=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph = ox.graph_from_gdfs(nodes, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del G, nodes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**** fin du traitement des données ****"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing(df):\n",
    "    return pd.DataFrame({'column_name': df.columns,\n",
    "                         'percent_missing': df.isnull().sum() * 100 / len(df)\n",
    "                         }).sort_values(by='percent_missing',ascending=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ox.geometries.geometries_from_place('marne' + ', Metropolitan France',\n",
    "                                        tags={'amenity': True}, \n",
    "                                     which_result=None, buffer_dist=None)\n",
    "missing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(CFG.data_path, f'[{CFG.area_name}]amenity_tags.feather')\n",
    "try:\n",
    "  tags = gpd.read_feather(file)\n",
    "except:\n",
    "    print('Datas not found on disk')\n",
    "    tags = gpd.GeoDataFrame()\n",
    "    total = len(AREA)\n",
    "    for n, area in enumerate(AREA):\n",
    "      print(f'Datas retrieved for {area}: {n+1}/{total} ~ {(n+1) / total:.2%}')\n",
    "      tags = pd.concat(\n",
    "        [tags,\n",
    "         ox.geometries.geometries_from_place(area + ', Metropolitan France',\n",
    "                                        tags={'amenity': True}, \n",
    "                                        which_result=None, buffer_dist=None)[['amenity','geometry']]\n",
    "        ]\n",
    "      )\n",
    "    tags.to_feather(file)\n",
    "\n",
    "display(tags.info())\n",
    "display(tags['amenity'].value_counts())\n",
    "\n",
    "del tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = os.path.join(CFG.data_path, f'[{CFG.area_name}]social_tags.feather')\n",
    "# try:\n",
    "#   social_tags = gpd.read_feather(file)\n",
    "# except:\n",
    "#     print('Datas not found on disk')\n",
    "#     social_tags = gpd.GeoDataFrame()\n",
    "#     total = len(AREA)\n",
    "#     for n, area in enumerate(AREA):\n",
    "#       print(f'Datas retrieved for {area}: {n+1}/{total} ~ {(n+1) / total:.2%}')\n",
    "#       social_tags = pd.concat(\n",
    "#         [social_tags,\n",
    "#          ox.geometries.geometries_from_place(area + ', Metropolitan France',\n",
    "#                                         tags={'amenity':['food_court',\n",
    "#                                                           'restaurant',\n",
    "#                                                           'arts_centre',\n",
    "#                                                           'cinema',\n",
    "#                                                           'community_centre',\n",
    "#                                                           'conference_centre',\n",
    "#                                                           'events_venue',\n",
    "#                                                           'exhibition_center',\n",
    "#                                                           'music_venue',\n",
    "#                                                           'planetarium',\n",
    "#                                                           'theatre'],\n",
    "#                                               }, \n",
    "#                                         which_result=None, buffer_dist=None)[['amenity','geometry',]]\n",
    "#         ]\n",
    "#       )\n",
    "#     # social_tags = social_tags[['amenity','geometry',]]\n",
    "#     social_tags.to_feather(file)\n",
    "\n",
    "# display(social_tags.info())\n",
    "# display(social_tags['amenity'].value_counts())\n",
    "\n",
    "# del social_tags"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ox.geometries.geometries_from_place('marne' + ', Metropolitan France',\n",
    "                                        tags={'historic':True }, \n",
    "                                     which_result=None, buffer_dist=None)\n",
    "missing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(CFG.data_path, f'[{CFG.area_name}]historic_tags.feather')\n",
    "try:\n",
    "  historic_tags = gpd.read_feather(file)\n",
    "except:\n",
    "    print('Datas not found on disk')\n",
    "    historic_tags = gpd.GeoDataFrame()\n",
    "    total = len(AREA)\n",
    "    for n, area in enumerate(AREA):\n",
    "      print(f'Datas retrieved for {area}: {n+1}/{total} ~ {(n+1) / total:.2%}')\n",
    "      historic_tags = pd.concat(\n",
    "        [historic_tags,\n",
    "         ox.geometries.geometries_from_place(area + ', Metropolitan France',\n",
    "                                        tags={'historic':True }, \n",
    "                                     which_result=None, buffer_dist=None)[['historic','geometry']]\n",
    "        ]\n",
    "      )\n",
    "    # historic_tags = historic_tags[['historic','amenity','geometry','source']]\n",
    "    historic_tags.to_feather(file)                                   \n",
    "\n",
    "display(historic_tags.info())\n",
    "display(historic_tags['historic'].value_counts())\n",
    "\n",
    "del historic_tags"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ox.geometries.geometries_from_place('marne' + ', Metropolitan France',\n",
    "                                        tags={'natural': True}, \n",
    "                                     which_result=None, buffer_dist=None)\n",
    "missing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file = os.path.join(CFG.data_path, f'[{CFG.area_name}]natural_tags.feather')\n",
    "try:\n",
    "  natural_tags = gpd.read_feather(file)\n",
    "except:\n",
    "    print('Datas not found on disk')\n",
    "    natural_tags = gpd.GeoDataFrame()\n",
    "    total = len(AREA)\n",
    "    for n, area in enumerate(AREA):\n",
    "      print(f'Datas retrieved for {area}: {n+1}/{total} ~ {(n+1) / total:.2%}')\n",
    "      natural_tags = pd.concat(\n",
    "        [natural_tags,\n",
    "         ox.geometries.geometries_from_place(area + ', Metropolitan France',\n",
    "                                        tags={'natural':True }, \n",
    "                                     which_result=None, buffer_dist=None)[['natural','geometry']]\n",
    "        ]\n",
    "      )\n",
    "    natural_tags.to_feather(file)                                   \n",
    "\n",
    "display(natural_tags.info())\n",
    "display(natural_tags['natural'].value_counts())\n",
    "\n",
    "del natural_tags"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charge Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = ox.geometries.geometries_from_place('marne' + ', Metropolitan France',\n",
    "#                                         tags={'amenity':['charging_station']}, \n",
    "#                                      which_result=None, buffer_dist=None)\n",
    "# missing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = os.path.join(CFG.data_path, f'[{CFG.area_name}]charge_tags.feather')\n",
    "# try:\n",
    "#   charge_tags = gpd.read_feather(file)\n",
    "# except:\n",
    "#     print('Datas not found on disk')\n",
    "#     charge_tags = gpd.GeoDataFrame()\n",
    "#     total = len(AREA)\n",
    "#     for n, area in enumerate(AREA):\n",
    "#       print(f'Datas retrieved for {area}: {n+1}/{total} ~ {(n+1) / total:.2%}')\n",
    "#       charge_tags = pd.concat(\n",
    "#         [charge_tags,\n",
    "#          ox.geometries.geometries_from_place(area + ', Metropolitan France',\n",
    "#                                         tags={'amenity':['charging_station']}, \n",
    "#                                      which_result=None, buffer_dist=None)\n",
    "#                                     #  [[\n",
    "#                                     # 'amenity', \n",
    "#                               #  'capacity',\n",
    "#                               #  'geometry',\n",
    "#       #                          'socket:type2',\n",
    "#       #                          'socket:typee',\n",
    "#       #                          'socket:type3', 'source','socket:tesla_supercharger',\n",
    "#       #  'socket:tesla_supercharger:output','socket:tesla_supercharger_ccs:output',\n",
    "#       #  'socket:type2_combo', 'socket:type2_combo:output','socket:chademo',\n",
    "#       #  'socket:type3c',\n",
    "#       # 'amperage',\n",
    "#       #  'voltage','socket:schuko','source:socket:type2:output', 'source:socket:typee',\n",
    "#       #  'capacity:charging', 'charging_station:output','socket:chademo:current',\n",
    "#       #  'socket:type2:current', 'socket:type2_combo:current'\n",
    "#                       # ]]\n",
    "#         ]\n",
    "#       )\n",
    "#     charge_tags = charge_tags[['amenity', \n",
    "#                                'capacity',\n",
    "#                                'geometry',\n",
    "#                                'socket:type2',\n",
    "#                                'socket:typee',\n",
    "#                                'socket:type3', 'source','socket:tesla_supercharger',\n",
    "#        'socket:tesla_supercharger:output','socket:tesla_supercharger_ccs:output',\n",
    "#        'socket:type2_combo', 'socket:type2_combo:output','socket:chademo',\n",
    "#        'socket:type3c','amperage',\n",
    "#        'voltage','socket:schuko','source:socket:type2:output', 'source:socket:typee',\n",
    "#        'capacity:charging', 'charging_station:output','socket:chademo:current',\n",
    "#        'socket:type2:current', 'socket:type2_combo:current'\n",
    "#                       ]]\n",
    "#     charge_tags.to_feather(file)                                                \n",
    "\n",
    "# display(charge_tags.info())\n",
    "# display(charge_tags['amenity'].value_counts())\n",
    "\n",
    "# del charge_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ox.geometries.geometries_from_place('marne' + ', Metropolitan France',\n",
    "                                        tags={'leisure':True}, \n",
    "                                     which_result=None, buffer_dist=None)\n",
    "missing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(CFG.data_path, f'[{CFG.area_name}]leisure_tags.feather')\n",
    "try:\n",
    "  leisure_tags = gpd.read_feather(file)\n",
    "except:\n",
    "    print('Datas not found on disk')\n",
    "    leisure_tags = gpd.GeoDataFrame()\n",
    "    total = len(AREA)\n",
    "    for n, area in enumerate(AREA):\n",
    "      print(f'Datas retrieved for {area}: {n+1}/{total} ~ {(n+1) / total:.2%}')\n",
    "      leisure_tags = pd.concat(\n",
    "        [leisure_tags,\n",
    "         ox.geometries.geometries_from_place(area + ', Metropolitan France',\n",
    "                                        tags={'leisure':True}, \n",
    "                                     which_result=None, buffer_dist=None)\n",
    "                                     [\n",
    "                                                                          [\n",
    "                                                                          'leisure',\n",
    "                                                                          'geometry',\n",
    "                                                                          ]\n",
    "                                                                           ]\n",
    "        ]\n",
    "      )\n",
    "    leisure_tags.to_feather(file)                                    \n",
    "\n",
    "display(leisure_tags.info())\n",
    "display(leisure_tags['leisure'].value_counts())\n",
    "\n",
    "del leisure_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ox.geometries.geometries_from_place('marne' + ', Metropolitan France',\n",
    "                                        tags={'sport':True}, \n",
    "                                     which_result=None, buffer_dist=None)\n",
    "missing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(CFG.data_path, f'[{CFG.area_name}]sport_tags.feather')\n",
    "try:\n",
    "  sport_tags = gpd.read_feather(file)\n",
    "except:\n",
    "    print('Datas not found on disk')\n",
    "    sport_tags = gpd.GeoDataFrame()\n",
    "    total = len(AREA)\n",
    "    for n, area in enumerate(AREA):\n",
    "      print(f'Datas retrieved for {area}: {n+1}/{total} ~ {(n+1) / total:.2%}')\n",
    "      sport_tags = pd.concat(\n",
    "        [sport_tags,\n",
    "         ox.geometries.geometries_from_place(area + ', Metropolitan France',\n",
    "                                        tags={'sport':True}, \n",
    "                                     which_result=None, buffer_dist=None)\n",
    "                                     [\n",
    "                                                                      ['sport', \n",
    "                                                                       'geometry']\n",
    "                                                                        ]\n",
    "        ]                                                               \n",
    "      )\n",
    "    \n",
    "    sport_tags.to_feather(file)\n",
    "                                  \n",
    "\n",
    "display(sport_tags.info())\n",
    "display(sport_tags['sport'].value_counts())\n",
    "\n",
    "del sport_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ox.geometries.geometries_from_place('marne' + ', Metropolitan France',\n",
    "                                        tags={'boundary':'administrative'}, \n",
    "                                     which_result=None, buffer_dist=None)\n",
    "missing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: rename file with []\n",
    "file = os.path.join(CFG.data_path, f'[{CFG.area_name}]boundaries.feather')\n",
    "try:\n",
    "  boundaries = gpd.read_feather(file)\n",
    "except:\n",
    "    print('Datas not found')\n",
    "    boundaries = gpd.GeoDataFrame()\n",
    "    total = len(AREA)\n",
    "    for n, area in enumerate(AREA):\n",
    "      print(f'Datas retrieved for {area}: {n+1}/{total} ~ {(n+1) / total:.2%}')\n",
    "      boundaries = pd.concat(\n",
    "        [boundaries,\n",
    "         ox.geometries.geometries_from_place(area + ', Metropolitan France',\n",
    "                                        tags={'boundary':'administrative'}, \n",
    "                                     which_result=1, buffer_dist=None)\n",
    "                    #                  [['name', \n",
    "                    #            'geometry',\n",
    "                    #   ]]\n",
    "        ]\n",
    "      )\n",
    "    boundaries = boundaries[[\n",
    "      'boundary','geometry','admin_level'\n",
    "    ]]\n",
    "    boundaries.to_feather(file)                                  \n",
    "\n",
    "display(boundaries.info())\n",
    "# tourism_tags['amenity'].value_counts()   \n",
    "boundaries                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ox.geometries.geometries_from_place('marne' + ', Metropolitan France',\n",
    "                                        tags={'tourism': True}, \n",
    "                                     which_result=None, buffer_dist=None)\n",
    "missing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(CFG.data_path, f'[{CFG.area_name}]tourism_tags.feather')\n",
    "try:\n",
    "  tourism_tags = gpd.read_feather(file)\n",
    "except:\n",
    "    print('Datas not found')\n",
    "    tourism_tags = gpd.GeoDataFrame()\n",
    "    total = len(AREA)\n",
    "    for n, area in enumerate(AREA):\n",
    "      print(f'Datas retrieved for {area}: {n+1}/{total} ~ {(n+1) / total:.2%}')\n",
    "      tourism_tags = pd.concat(\n",
    "        [tourism_tags,\n",
    "         ox.geometries.geometries_from_place(area + ', Metropolitan France',\n",
    "                                        tags={'tourism': True}, \n",
    "                                     which_result=None, buffer_dist=None)\n",
    "                                     [['tourism', \n",
    "                               'geometry',\n",
    "                      ]]\n",
    "        ]\n",
    "      )\n",
    "   \n",
    "    tourism_tags.to_feather(file)                                  \n",
    "\n",
    "display(tourism_tags.info())\n",
    "display(tourism_tags['tourism'].value_counts())\n",
    "\n",
    "del tourism_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: get each commune Mairie coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: merge decoupage with osm_id and Mairies coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*    End of OSM datasets file retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add isom_id to communes decoupage, for graph building\n",
    "\n",
    "import requests, io\n",
    "data_path = './datas'\n",
    "file_name = 'decoupage_administratif'\n",
    "ext = '.json'\n",
    "url ='https://www.data.gouv.fr/fr/datasets/r/fb3580f6-e875-408d-809a-ad22fc418581'\n",
    "\n",
    "\n",
    "# import requests\n",
    "# from requests.adapters import HTTPAdapter\n",
    "# import urllib3\n",
    "# from urllib3 import Retry\n",
    "\n",
    "# session = requests.Session()\n",
    "# headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36'}\n",
    "# session.headers.update(headers)\n",
    "# adapter = HTTPAdapter(max_retries=Retry(total=10, backoff_factor=1))\n",
    "# session.mount(\"http://\", adapter)\n",
    "# session.mount(\"https://\", adapter)\n",
    "\n",
    "# def get_(url):\n",
    "#     response = session.get(url.strip())\n",
    "#     return response.json()\n",
    "# # GET COORDINATES FROM CITY NAME\n",
    "\n",
    "# def get_place_osmid(county,city, country):\n",
    "#     url  =  'https://nominatim.openstreetmap.org/search?'\n",
    "#     # url += f'q={adress}%2C+'\n",
    "#     url += f'city={city}&'\n",
    "#     url += f'country={country}&'\n",
    "#     url += f'county={county}&'\n",
    "\n",
    "\n",
    "#     url +=  'format=geojson'#&polygon_geojson=1'\n",
    "#     return get_(url)\n",
    "\n",
    "\n",
    "# def get_osm_infos(gdf):\n",
    "#     total = gdf.shape[0]\n",
    "#     for i, (n, row) in enumerate(gdf.iterrows()):\n",
    "#         print(f'{i/total:.2%}                   ', end='\\r')\n",
    "\n",
    "#         data = get_place_osmid('', row['libgeo'], 'France')\n",
    "\n",
    "#         try:\n",
    "#             gdf.loc[n, 'osm_id'] = data['features'][0]['properties']['osm_id']\n",
    "#         except:\n",
    "#             gdf.loc[n, 'osm_id'] = None\n",
    "#         try:\n",
    "#             gdf.loc[n, 'place_id'] = data['features'][0]['properties']['place_id']\n",
    "#         except:\n",
    "#             gdf.loc[n, 'place_id'] = None\n",
    "#         try:\n",
    "#             gdf.loc[n, 'place_rank'] = data['features'][0]['properties']['place_rank']\n",
    "#         except:\n",
    "#             gdf.loc[n, 'place_rank'] = None\n",
    "#         try:\n",
    "#             gdf.loc[n, 'display_name'] = data['features'][0]['properties']['display_name']\n",
    "#         except:\n",
    "#             gdf.loc[n, 'display_name'] = None\n",
    "#         try:\n",
    "#             gdf.loc[n, 'importance'] = data['features'][0]['properties']['importance']\n",
    "#         except:\n",
    "#             gdf.loc[n, 'importance'] = None\n",
    "            \n",
    "#     return gdf\n",
    "\n",
    "\n",
    "# try: \n",
    "#     print('Loading data from local file...')\n",
    "#     decoupage = gpd.read_feather(os.path.join(data_path,file_name + '.feather'))\n",
    "    \n",
    "# except:\n",
    "#     print('Loading data from url...')\n",
    "\n",
    "#     s = requests.get(url).content\n",
    "#     decoupage = pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "    \n",
    "#     print('Saving data to local file...')\n",
    "#     decoupage.to_feather(os.path.join(data_path,file_name + '.feather'))\n",
    "\n",
    "# # Check if osm_id is present and complete gdf if needed\n",
    "# if 'osm_id' not in decoupage.columns:\n",
    "#     print('Adding osm feature (approx 5 hours to complete!!!)')\n",
    "#     decoupage = get_osm_infos(decoupage)\n",
    "#     print('Saving data to local file...')\n",
    "#     decoupage.to_feather(os.path.join(data_path,file_name + '.feather'))\n",
    "\n",
    "# display(decoupage.info())\n",
    "# display(decoupage.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './datas'\n",
    "file_name = 'decoupage_administratif'\n",
    "decoupage = gpd.read_feather(os.path.join(data_path,file_name + '.feather'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoupage.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from requests.adapters import HTTPAdapter\n",
    "# import urllib3\n",
    "# from urllib3 import Retry\n",
    "\n",
    "# session = requests.Session()\n",
    "# headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36'}\n",
    "# session.headers.update(headers)\n",
    "# adapter = HTTPAdapter(max_retries=Retry(total=10, backoff_factor=1))\n",
    "# session.mount(\"http://\", adapter)\n",
    "# session.mount(\"https://\", adapter)\n",
    "\n",
    "# def get_(url):\n",
    "#     response = session.get(url.strip())\n",
    "#     return response.json()\n",
    "# # GET COORDINATES FROM CITY NAME\n",
    "\n",
    "# def get_place_osmid(county,city, country):\n",
    "#     url  =  'https://nominatim.openstreetmap.org/search?'\n",
    "#     # url += f'q={adress}%2C+'\n",
    "#     url += f'city={city}&'\n",
    "#     url += f'country={country}&'\n",
    "#     url += f'county={county}&'\n",
    "\n",
    "\n",
    "#     url +=  'format=geojson'#&polygon_geojson=1'\n",
    "#     return get_(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import concurrent.futures\n",
    "\n",
    "\n",
    "\n",
    "# def get_osm_infos(gdf):\n",
    "#     total = gdf.shape[0]\n",
    "#     for i, (n, row) in enumerate(gdf.iterrows()):\n",
    "#         print(f'{i/total:.2%}                   ', end='\\r')\n",
    "#         data = get_place_osmid('', row['libgeo'], 'France')\n",
    "#         gdf.loc[n, 'osm_id'] = data['features'][0]['properties']['osm_id']\n",
    "#         gdf.loc[n, 'place_id'] = data['features'][0]['properties']['place_id']\n",
    "#         gdf.loc[n, 'place_rank'] = data['features'][0]['properties']['place_rank']\n",
    "#         gdf.loc[n, 'display_name'] = data['features'][0]['properties']['display_name']\n",
    "#         gdf.loc[n, 'importance'] = data['features'][0]['properties']['importance']\n",
    "#     return gdf\n",
    "\n",
    "\n",
    "# def multi_process_osmid(gdf, processes=4):\n",
    "#     # Split the DataFrame into four equal chunks\n",
    "#     num_chunks = processes\n",
    "#     chunk_size = len(gdf) // num_chunks\n",
    "#     gdf_chunks = [gdf[i:i+chunk_size].copy() for i in range(0, len(gdf), chunk_size)]\n",
    "\n",
    "#     # Create a ThreadPoolExecutor to process chunks asynchronously\n",
    "#     with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "#         # Submit the processing function for each chunk\n",
    "#         futures = [executor.submit(get_osm_infos, chunk) for chunk in gdf_chunks]\n",
    "\n",
    "#         # Wait for all futures to complete\n",
    "#         concurrent.futures.wait(futures)\n",
    "\n",
    "#         # Get the results from the completed futures\n",
    "#         results = pd.concat([future.result() for future in futures] )\n",
    "#     return results       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoupage = get_osm_infos(decoupage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoupage = multi_process_osmid(decoupage, processes=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "E-Motion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
