{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auteur: Michaël Leroy\n",
    "\n",
    "# Contenu:\n",
    "\n",
    "[+] Données\n",
    "\n",
    "    + Chargement des open datas + sauvegarde locale\n",
    "\n",
    "    + Aggregation des tables:\n",
    "\n",
    "        + Communes:\n",
    "            + Communes france métro, données demographiques, geometrie, nb véhicules, nb VE, code insee, region, département, pourcentage VE/habitants\n",
    "        * Bornes de charge:\n",
    "            + dédoublonnage des pdc ayant les mêmes géolocalisations et caractéristiques\n",
    "            + toutes les caractéristiques regroupées dans popup_html\n",
    "            + puissance_nominale et nb_pdc par bornes\n",
    "            \n",
    "        * toutes les agrégations sur le code commune insee, \n",
    "        * Zone france métro + corse (compatible avec trajet routier)\n",
    "\n",
    "[+] Communes:\n",
    "\n",
    "    date_arrete:\n",
    "            2020-12-31\n",
    "            2021-03-31\n",
    "            2021-06-30\n",
    "            2021-09-30\n",
    "            2021-12-31\n",
    "            2022-03-31\n",
    "            2022-06-30\n",
    "            2022-09-30\n",
    "            2022-12-31\n",
    "\n",
    "\n",
    "    <class 'geopandas.geodataframe.GeoDataFrame'>\n",
    "    Int64Index: 34821 entries, 0 to 34954\n",
    "    Data columns (total 8 columns):\n",
    "    #   Column        Non-Null Count  Dtype   \n",
    "    ---  ------        --------------  -----   \n",
    "    0   insee         34821 non-null  object  \n",
    "    1   nom           34821 non-null  object  \n",
    "    2   geometry      34821 non-null  geometry\n",
    "    3   dep           34821 non-null  object  \n",
    "    4   dep_name      34821 non-null  object  \n",
    "    5   region_name   34821 non-null  object  \n",
    "    6   VE_per_inhab  34815 non-null  float64 \n",
    "    7   html_popup    34821 non-null  object  \n",
    "    dtypes: float64(1), geometry(1), object(6)\n",
    "    memory usage: 2.4+ MB\n",
    "\n",
    "[+] Bornes\n",
    "\n",
    "    <class 'geopandas.geodataframe.GeoDataFrame'>\n",
    "    RangeIndex: 17623 entries, 0 to 17622\n",
    "    Data columns (total 4 columns):\n",
    "    #   Column              Non-Null Count  Dtype   \n",
    "    ---  ------              --------------  -----   \n",
    "    0   nbre_pdc            17623 non-null  float64 \n",
    "    1   puissance_nominale  17623 non-null  float64 \n",
    "    2   geometry            17623 non-null  geometry\n",
    "    3   html_popup          17623 non-null  object  \n",
    "    dtypes: float64(2), geometry(1), object(1)\n",
    "    memory usage: 550.8+ KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.notebook import tqdm\n",
    "# from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "\n",
    "# Data management\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from folium.features import Choropleth\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap\n",
    "\n",
    "\n",
    "# I/O\n",
    "import gc\n",
    "import io, requests\n",
    "import zipfile, shutil\n",
    "import joblib\n",
    "\n",
    "# tqdm().pandas()\n",
    "\n",
    "# data_path = 'C:/Users/demo/Desktop/Lattitude/datas/'\n",
    "data_path = 'datas'\n",
    "os.makedirs(data_path, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bornes de recharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'consolidation-etalab-schema-irve-statique-v-2.2.0-20230327'\n",
    "ext = '.json'\n",
    "url = 'https://www.data.gouv.fr/fr/datasets/r/7eee8f09-5d1b-4f48-a304-5e99e8da1e26'\n",
    "\n",
    "try: \n",
    "    print('Loading data from local file...')\n",
    "    bornes = gpd.read_feather(os.path.join(data_path,file_name + '.feather'))\n",
    "    \n",
    "except:\n",
    "    print('Loading data from url...')\n",
    "    # from url\n",
    "    bornes = gpd.read_file( url)\n",
    "\n",
    "    # bornes = gpd.read_file(os.path.join(data_path,file_name + ext))\n",
    "    print('Saving data to local file...')\n",
    "    bornes.to_feather(os.path.join(data_path,file_name + '.feather'))\n",
    "\n",
    "display(bornes.info() )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folium map centered on the first row of datas_\n",
    "centroid = list(bornes.iloc[0].geometry.centroid.coords[0])\n",
    "display(centroid, centroid[::-1])\n",
    "\n",
    "\n",
    "# create a folium map\n",
    "m = folium.Map(location=[*centroid[::-1]], zoom_start=7)#, crs='EPSG3857')\n",
    "display(m)\n",
    "del m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_strings_bools(val):\n",
    "    if val.lower() == 'true':\n",
    "        return True\n",
    "    elif val.lower() == 'false':\n",
    "        return False\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "# find all columns that contain the string values 'True', 'true', 'False', or 'false',\n",
    "#  convert those values to boolean, and set the column type to boolean\n",
    "bool_columns = bornes.applymap(lambda x: isinstance(x, str) and x.lower() in ['true', 'false']).any()\n",
    "bornes.loc[:, bool_columns] = bornes.loc[:, bool_columns].applymap(convert_strings_bools).astype(bool)\n",
    "bornes.info()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in bornes.select_dtypes(include='object').columns:\n",
    "    try :\n",
    "        bornes[col] = bornes[col].astype('float')\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "bornes.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types de voitures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'voitures-par-commune-par-energie'\n",
    "ext = '.geojson'\n",
    "url = 'http://opendata.agenceore.fr/explore/dataset/voitures-par-commune-par-energie/download?format=geojson&timezone=Europe/Berlin&use_labels_for_header=false'\n",
    "\n",
    "try: \n",
    "    print('Loading data from local file...')\n",
    "    cars = gpd.read_feather(os.path.join(data_path,file_name + '.feather'))\n",
    "except:\n",
    "    print('Loading data from url...')\n",
    "    # from url\n",
    "    s = requests.get(url).content\n",
    "    cars = gpd.read_file(io.StringIO(s.decode('utf-8')))\n",
    "\n",
    "    # avoiding multi dowloads for GES emmision lowering\n",
    "    print('Saving data to local file...')\n",
    "    cars.to_feather(os.path.join(data_path,file_name + '.feather'))\n",
    "\n",
    "print(cars.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Découpage  Administratif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "file_name = 'decoupage_administratif'\n",
    "ext = '.json'\n",
    "url ='https://www.data.gouv.fr/fr/datasets/r/fb3580f6-e875-408d-809a-ad22fc418581'\n",
    "# temp_path = 'temp_unzip'\n",
    "\n",
    "\n",
    "try: \n",
    "    print('Loading data from local file...')\n",
    "    decoupage = gpd.read_feather(os.path.join(data_path,file_name + '.feather'))\n",
    "except:\n",
    "    print('Loading data from url...')\n",
    "\n",
    "    s = requests.get(url).content\n",
    "    decoupage = gpd.read_file(io.StringIO(s.decode('utf-8')))\n",
    "    \n",
    "    print('Saving data to local file...')\n",
    "    decoupage.to_feather(os.path.join(data_path,file_name + '.feather'))\n",
    "\n",
    "decoupage.info()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Departements et régions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'depatements-regions'\n",
    "ext = '.csv'\n",
    "url ='https://www.data.gouv.fr/fr/datasets/r/987227fb-dcb2-429e-96af-8979f97c9c84'\n",
    "# temp_path = 'temp_unzip'\n",
    "\n",
    "\n",
    "try: \n",
    "    print('Loading data from local file...')\n",
    "    regions = pd.read_feather(os.path.join(data_path,file_name + '.feather'))\n",
    "except:\n",
    "    print('Loading data from url...')\n",
    "\n",
    "    s = requests.get(url).content\n",
    "    regions = pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "    \n",
    "    print('Saving data to local file...')\n",
    "    regions.to_feather(os.path.join(data_path,file_name + '.feather'))\n",
    "\n",
    "regions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'communes-20220101'\n",
    "ext = '.shp'\n",
    "url ='https://www.data.gouv.fr/fr/datasets/r/0e117c06-248f-45e5-8945-0e79d9136165'\n",
    "temp_path = 'temp_unzip'\n",
    "\n",
    "\n",
    "try: \n",
    "    print('Loading data from local file...')\n",
    "    communes = gpd.read_feather(os.path.join(data_path,file_name + '.feather'))\n",
    "except:\n",
    "    print('Loading data from url...')\n",
    "    # Zip file from url  \n",
    "    zip_file = requests.get(url)\n",
    "    os.makedirs(temp_path, exist_ok=True)\n",
    "    with zipfile.ZipFile(io.BytesIO(zip_file.content)) as archive:\n",
    "        archive.extractall(temp_path)\n",
    "    communes = gpd.read_file(os.path.join(temp_path,file_name + ext))   \n",
    "    shutil.rmtree(temp_path) \n",
    "    \n",
    "    print('Saving data to local file...')\n",
    "    communes.to_feather(os.path.join(data_path,file_name + '.feather'))\n",
    "\n",
    "communes.info()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Données démographiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "file_name = 'Communes'\n",
    "ext = '.csv'\n",
    "url ='https://www.insee.fr/fr/statistiques/fichier/4265429/ensemble.zip'\n",
    "temp_path = 'temp_unzip'\n",
    "\n",
    "\n",
    "try: \n",
    "    print('Loading data from local file...')\n",
    "    pop_communes = pd.read_feather(os.path.join(data_path,file_name + '.feather'))\n",
    "except:\n",
    "    print('Loading data from url...')\n",
    "    # Zip file from url  \n",
    "    zip_file = requests.get(url)\n",
    "    os.makedirs(temp_path, exist_ok=True)\n",
    "    with zipfile.ZipFile(io.BytesIO(zip_file.content)) as archive:\n",
    "        archive.extractall(temp_path)\n",
    "    pop_communes = pd.read_csv(os.path.join(temp_path,file_name + ext), sep=';')     \n",
    "    shutil.rmtree(temp_path) \n",
    "\n",
    "    # Rename the columns\n",
    "    pop_communes.rename(columns={'DEPCOM': 'insee'}, inplace=True)\n",
    "    \n",
    "    print('Saving data to local file...')\n",
    "    pop_communes.to_feather(os.path.join(data_path,file_name + '.feather'))\n",
    "\n",
    "pop_communes.info()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communes and cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cars.head(2), cars.shape, len(set(cars.codgeo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = communes.join(pop_communes.drop('COM',axis=1).set_index('insee'), \n",
    "                      on='insee',\n",
    "                      how='left', \n",
    "                      validate='1:1'\n",
    "                        )\\\n",
    "                .join(cars.rename(columns={'codgeo': 'insee'}).drop('geometry',axis=1).set_index('insee'), \n",
    "                      on='insee', \n",
    "                      how='left', \n",
    "                      # rsuffix='_cars',\n",
    "                      validate='1:m'\n",
    "                      )\\\n",
    "            #     .join(bornes.rename(columns={'consolidated_code_postal': 'insee'}).set_index('insee'), \n",
    "            #           on='insee', \n",
    "            #           how='left', \n",
    "            #           rsuffix='_bornes',\n",
    "            #           validate='m:m')\n",
    "\n",
    "del pop_communes            \n",
    "datas.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création dep en prennant les deux premiers str de insee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas['dep'] = datas['insee'].apply(lambda s : s[0:2])\n",
    "\n",
    "\n",
    "display(regions.head(2), regions.shape, len(set(datas.dep)))\n",
    "\n",
    "set(regions.num_dep) - set(datas.dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = datas.join(regions.rename(columns={'num_dep': 'dep'}).set_index('dep'), on='dep', how='left', validate='m:1')\n",
    "\n",
    "# del regions\n",
    "datas.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create some metric on electrics stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas['VE_pct'] = datas.nb_vp_rechargeables_el / datas.nb_vp\n",
    "datas['VE_per_inhab'] = datas.nb_vp_rechargeables_el / datas.PMUN\n",
    "datas['VE_per_ha'] = datas.nb_vp_rechargeables_el / datas.surf_ha\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create html popup column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_popup(df):\n",
    "    texts = []\n",
    "\n",
    "    # loop on rows\n",
    "    for index, row in df.iterrows():\n",
    "        text = ''\n",
    "        for col in communes_info_cols:\n",
    "            text += f'<b>{col}:</b> {row[col]}<br>'\n",
    "        texts.append(text)\n",
    "    return texts    \n",
    "\n",
    "# list of columns from datas_ to be displayed\n",
    "communes_info_cols = datas.columns.tolist()\n",
    "communes_info_cols.remove('geometry')\n",
    "communes_info_cols.remove('wikipedia')\n",
    "communes_info_cols.remove('libgeo')\n",
    "communes_info_cols.remove('nb_vp_rechargeables_gaz')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "datas['html_popup'] = single_popup(datas)   \n",
    "datas.html_popup.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save communes par date_arrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'dataset_communes'\n",
    "\n",
    "file_name_dict = dict()\n",
    "\n",
    "for date in datas.date_arrete.value_counts().sort_index().index:\n",
    "    print(date)\n",
    "    tmp = datas.query(\"date_arrete == @date\").copy()\n",
    "    tmp.drop(\n",
    "        [\n",
    "        # 'insee',\n",
    "        # 'nom', \n",
    "        'wikipedia', \n",
    "        'surf_ha', \n",
    "        # 'geometry', \n",
    "        'PMUN', \n",
    "        'PCAP',\n",
    "        'PTOT', \n",
    "        'nb_vp', \n",
    "        'libepci', \n",
    "        'libgeo', \n",
    "        'nb_vp_rechargeables_gaz',\n",
    "        'date_arrete', \n",
    "        'epci', \n",
    "        'nb_vp_rechargeables_el', \n",
    "        # 'dep', \n",
    "        # 'dep_name',\n",
    "        # 'region_name', \n",
    "        'VE_pct', \n",
    "        # 'VE_per_inhab', \n",
    "        'VE_per_ha', \n",
    "        # 'html_popup'\n",
    "        ], \n",
    "        axis=1, \n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    tmp.dropna( subset='region_name', axis=0, inplace=True) \n",
    "\n",
    "    tmp.fillna('n.r.') \n",
    "    \n",
    "    # Save by region to feather and keep a file catalog for future use\n",
    "    list_files = []\n",
    "    for region in tmp.region_name.unique():\n",
    "        # print(region)\n",
    "        region_cut = region[:5]\n",
    "        file_ = f'{file_name}_{region_cut}_{date}.feather'\n",
    "        list_files.append(file_)\n",
    "        tmp.query(\"region_name == @region\")\\\n",
    "            .to_feather(os.path.join(data_path, file_)\n",
    "                    # compression='zstd'\n",
    "        )\n",
    "    file_name_dict[date] = list_files   \n",
    "# dump catalog to disk\n",
    "joblib.dump(file_name_dict, os.path.join(data_path,'file_catalog.joblib'))     \n",
    "tmp.plot()\n",
    "display(tmp.info())\n",
    "del tmp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bornes de charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bornes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bornes.sort_values(by='date_mise_en_service', inplace=True)\n",
    "display(bornes.head(2), bornes.shape, len(set(bornes.consolidated_code_postal)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en reprennant les codes insee et polygons de datas,  creation de insee dans bornes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the GeoDataFrames to a dask DataFrame\n",
    "com_ = communes[['insee','geometry']]\n",
    "bor_ = bornes[['consolidated_code_postal','geometry']]\n",
    "\n",
    "\n",
    "# display(com_.shape[0], bor_.shape[0])\n",
    "\n",
    "bornes['insee'] = gpd.sjoin(com_, bor_,  how='right', predicate='contains',lsuffix='_com', rsuffix='_bor')['insee'].astype(str)\n",
    "bornes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dep, dep_name, region_name\n",
    "\n",
    "bornes['dep'] = bornes['insee'].apply(lambda s : s[0:2])\n",
    "\n",
    "bornes = bornes.join(regions.rename(columns={'num_dep': 'dep'}).set_index('dep'), on='dep', how='left', validate='m:1')\n",
    "\n",
    "\n",
    "\n",
    "# del regions, communes, com_, bor_\n",
    "bornes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Nan\n",
    "bornes[bornes.insee.isna()].consolidated_is_lon_lat_correct.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dédoublonnage bornes de charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bornes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = bornes.drop(columns=[\n",
    "    'coordonneesXY',\n",
    "    'observations',\n",
    "    'date_maj', \n",
    "    'last_modified', 'datagouv_dataset_id',\n",
    "       'datagouv_resource_id', 'datagouv_organization_or_owner',\n",
    "       'consolidated_longitude', 'consolidated_latitude',\n",
    "       'consolidated_code_postal', 'consolidated_commune',\n",
    "       'consolidated_is_lon_lat_correct',\n",
    "       'consolidated_is_code_insee_verified',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.dropna( subset='region_name', inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp.cx[-5:10, 41:54]\n",
    "tmp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get nbre_pdc by geometry\n",
    "tmp.dissolve(by='insee',\n",
    "             aggfunc={\n",
    "            'nbre_pdc': list\n",
    "             },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View on TAVERNY pdcs\n",
    "tmp.query(\"insee == '95607'\")[['insee','nom_station','nbre_pdc','geometry','puissance_nominale', 'prise_type_ef', 'prise_type_2',\n",
    "       'prise_type_combo_ccs', 'prise_type_chademo', 'prise_type_autre']].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group pdc by coordinates\n",
    "\n",
    "# get x, y from geomerty\n",
    "tmp['X'] = tmp.geometry.x\n",
    "tmp['Y'] = tmp.geometry.y\n",
    "\n",
    "# groupby x,y and take first occurnce\n",
    "tmp = tmp.groupby(by=['X','Y']).agg('first').reset_index(drop=True)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check aggregation\n",
    "tmp.query(\"insee == '95607'\")[['insee','nom_station','nbre_pdc','geometry','puissance_nominale', 'prise_type_ef', 'prise_type_2',\n",
    "       'prise_type_combo_ccs', 'prise_type_chademo', 'prise_type_autre']].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create html popup column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.drop(columns=['raccordement','code_insee_commune'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp= tmp.loc[ :,   \n",
    "    [\n",
    "      'nom_amenageur', 'id_pdc_itinerance', 'gratuit',\n",
    "      'siren_amenageur', 'id_pdc_local', 'paiement_acte',\n",
    "      'contact_amenageur','nbre_pdc', 'paiement_cb',\n",
    "      'nom_operateur', 'puissance_nominale','paiement_autre',\n",
    "      'contact_operateur', 'prise_type_ef','tarification',\n",
    "      'telephone_operateur','prise_type_2','condition_acces',\n",
    "      'nom_enseigne','prise_type_combo_ccs', 'reservation',\n",
    "      'id_station_itinerance', 'prise_type_chademo','horaires',\n",
    "      'id_station_local',  'prise_type_autre','accessibilite_pmr',\n",
    "      'nom_station', 'cable_t2_attache','restriction_gabarit', \n",
    "      'implantation_station','num_pdl','station_deux_roues',\n",
    "      'adresse_station','insee','dep',\n",
    "      'date_mise_en_service', 'dep_name',  'region_name'  , \n",
    "       \n",
    "        \n",
    "      \n",
    "         \n",
    "        \n",
    "       \n",
    "      'geometry' \n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names generator \n",
    "def split_list(list_a, chunk_size):\n",
    "  for i in range(0, len(list_a), chunk_size):\n",
    "    yield list_a[i:i + chunk_size]\n",
    "\n",
    "\n",
    "def column_popup(df, info_cols,num_cols=3,width=20):\n",
    "    # Mise en page\n",
    "    num_cols = 3\n",
    "    width = 20\n",
    "    px = np.ceil(width / num_cols / 2)\n",
    "\n",
    "    texts = []\n",
    "\n",
    "    # Loop on rows\n",
    "    for index, row in df.iterrows():\n",
    "        text = f'<table style=\"width:{width}%\"><tr>'\n",
    "        # Create header\n",
    "        for n in range(num_cols):\n",
    "          text += f'<td style=\"font-weight:bold\">{n}</td>'\n",
    "        # lines\n",
    "        for cols in split_list(bornes_info_cols,num_cols):\n",
    "                text += '<tr>'\n",
    "                for col in cols:\n",
    "                        text += f'<th style=\"width:{px}%\"><b>{col}:</b><br> {row[col]}</th>' \n",
    "                text  += '</tr>'\n",
    "        # ends table         \n",
    "        text += '</table>'\n",
    "        # append to previous\n",
    "        texts.append(text)\n",
    "    \n",
    "    return texts\n",
    "\n",
    " # list of columns from datas_ to be displayed\n",
    "bornes_info_cols = tmp.columns.tolist()\n",
    "bornes_info_cols.remove('geometry')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tmp['html_popup'] = column_popup(tmp, info_cols=bornes_info_cols)   \n",
    "tmp.html_popup.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bornes_info_cols.remove('puissance_nominale')\n",
    "\n",
    "bornes_info_cols.remove('nbre_pdc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(tmp.columns) - set ( bornes_info_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.drop(bornes_info_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.plot(column='puissance_nominale', legend=True, figsize=(10,10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "\n",
    "### Save to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save bornes\n",
    "file_name = 'dataset_charge_points'\n",
    "print('Saving bornes to local file...')\n",
    "tmp.to_feather(os.path.join(data_path,file_name + '.feather'),\n",
    "                # compression='zstd'\n",
    "                )\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
